{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "f1 = \"../Data/blogData_train.csv\"\n",
    "f2 = \"../Data/blogData_test.csv\"\n",
    "train = pd.read_csv(f1, names=[\"V\"+str(x) if x != 281 else \"y\" for x in range(1, 282)])\n",
    "test = pd.read_csv(f2, names=[\"V\"+str(x) if x != 281 else \"y\" for x in range(1, 282)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = train.append(test,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_col = [65,73,74,76,80,81,84,85,87,90,91,92,94,95,97,98,\\\n",
    "              109,111,113,123,124,126,130,132,133,148,149,155,\\\n",
    "              156,161,166,167,169,172,173,178,179,190,198,199,\\\n",
    "              200,204,209,212,217,223,224,236,243,244,250,256,262]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in remove_col:\n",
    "    train = train.drop(\"V\"+str(c), axis=1)\n",
    "    test = test.drop(\"V\"+str(c), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"y\"] = np.log(train[\"y\"]+1)\n",
    "test[\"y\"] = np.log(test[\"y\"]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = set(range(63, 263)) - set(remove_col)\n",
    "cols = [\"V\"+str(x) for x in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isFreq(tp):\n",
    "    p = 0.4\n",
    "    all_appear = combined[tp[0]] > 0\n",
    "    for word in tp[1:]:\n",
    "        all_appear = all_appear & (combined[word] > 0)\n",
    "    all_appear_cnt = all_appear.sum()\n",
    "    for word in tp:\n",
    "        word_cnt = combined[word].sum()\n",
    "        if all_appear_cnt < p*word_cnt:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_word_pat = []\n",
    "# find pair of words that frequently appears together \n",
    "for i in range(len(cols)-1):\n",
    "    word_i = cols[i]\n",
    "    for j in range(i+1, len(cols)):\n",
    "        word_j = cols[j]\n",
    "        if isFreq((word_i, word_j)):\n",
    "            freq_word_pat.append((word_i, word_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apriori pattern grow\n",
    "freq_n_tp = freq_word_pat\n",
    "while len(freq_n_tp) > 1:\n",
    "    freq_np1_tp = []\n",
    "    n = len(freq_n_tp[0])\n",
    "    for i in range(len(freq_n_tp)):\n",
    "        common_pat = freq_n_tp[i][:(n-1)]\n",
    "        for j in range(i+1,len(freq_n_tp)):\n",
    "            if freq_n_tp[j][:(n-1)] != common_pat:\n",
    "                break\n",
    "            elif (freq_n_tp[i][1:]+freq_n_tp[j][-1:]) not in freq_n_tp:\n",
    "                continue\n",
    "            else:\n",
    "                potential_tp = freq_n_tp[i] + freq_n_tp[j][-1:]\n",
    "                if isFreq(potential_tp):\n",
    "                    freq_np1_tp.append(potential_tp)\n",
    "    freq_word_pat += freq_np1_tp\n",
    "    freq_n_tp = freq_np1_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop freq pattern that only appear in train or test dataset\n",
    "to_remove = []\n",
    "for tp in freq_word_pat:\n",
    "    test_exist = test[tp[0]] > 0\n",
    "    for col in tp[1:]:\n",
    "        test_exist = test_exist & (test[col] > 0)\n",
    "    test_cnt = test_exist.sum()\n",
    "    if test_cnt == .0:\n",
    "        to_remove.append(tp)\n",
    "        continue\n",
    "    train_exist = train[tp[0]] > 0\n",
    "    for col in tp[1:]:\n",
    "        train_exist = train_exist & (train[col] > 0)\n",
    "    train_cnt = train_exist.sum()\n",
    "    if train_cnt == .0:\n",
    "        freq_word_pat.remove(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate feature\n",
    "for tp in freq_word_pat:\n",
    "    colname = '_'.join(tp)\n",
    "    train_exist = train[tp[0]] > 0\n",
    "    for col in tp[1:]:\n",
    "        train_exist = train_exist & (train[col] > 0)\n",
    "    train[colname] = train_exist.astype(float)\n",
    "    test_exist = test[tp[0]] > 0\n",
    "    for col in tp[1:]:\n",
    "        test_exist = test_exist & (test[col] > 0)\n",
    "    test[colname] = test_exist.astype(float)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"addFeatureTrain.csv\", index=False)\n",
    "test.to_csv(\"addFeatureTest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
