names(test)[281] = "y"
x_train = train[,-281]
y_train = train[,281]
x_test = test[,-281]
y_test = test[,281]
# evaluation function
eva = function(test_pred, test_real){
return(mean((log(1+test_real)-test_pred)^2))
}
###############################################################
# linear regression
fit = lm(log(y+1)~., data=train)
lm_pred = predict(fit,newdata = x_test)
err_lm = eva(lm_pred, y_test)
plot(fit)
breakpoint = seq(1,nrow(comp_sort_pred),1000)
breakpoint = c(breakpoint,nrow(comp_sort_pred))
groupMean = c()
for (i in 1:8){
groupMean = c(groupMean,
mean(comp_sort_pred[breakpoint[i]:(breakpoint[i+1]-1),"y_test"]))
}
# some underestimate and overestimate exist
qplot(glm_pred-log(1+y_test),main = "residual distribution",
xlab = "residual")
# underestimate is more serious in this model, meaning the inflated 0
# cause much bias of this model
# The assumption of poisson distribtuon did not improve the accuracy
# very much
qplot(y=log(1+y_test)-glm_pred,x=glm_pred,main = "Residuals vs Fitted",
xlab = "Fitted values", ylab = "Residuals",ylim = c(-13,8))
comp = cbind(lm_pred,y_test)
comp_sort_pred = comp[order(lm_pred),]
breakpoint = seq(1,nrow(comp_sort_pred),1000)
breakpoint = c(breakpoint,nrow(comp_sort_pred))
groupMean = c()
for (i in 1:8){
groupMean = c(groupMean,
mean(comp_sort_pred[breakpoint[i]:(breakpoint[i+1]-1),"y_test"]))
}
qplot(glm_pred-log(1+y_test),main = "residual distribution",
xlab = "residual")
# underestim
qplot(lm_pred-log(1+y_test),main = "residual distribution",
xlab = "residual")
qplot(lm_pred-log(1+y_test),main = "residual distribution",
xlab = "residual")
# underestimate is more serious in this model, meaning the inflated 0
# cause much bias of this model
# The assumption of poisson distribtuon did not improve the accuracy
# very much
qplot(y=log(1+y_test)-lm_pred,x=lm_pred,main = "Residuals vs Fitted",
xlab = "Fitted values", ylab = "Residuals",ylim = c(-13,8))
theme_set(theme_gray(base_size = 18))
qplot(lm_pred-log(1+y_test),main = "residual distribution",
xlab = "residual",)
qplot(lm_pred-log(1+y_test),main = "residual distribution",
xlab = "residual",bins=30)
# very much
qplot(y=log(1+y_test)-lm_pred,x=lm_pred,main = "Residuals vs Fitted",
xlab = "Fitted values", ylab = "Residuals",ylim = c(-13,8))
theme_set(theme_gray(base_size = 18))
qplot(lm_pred-log(1+y_test),main = "residual distribution",
xlab = "residual",bins=30)
qplot(y=lm_pred-log(1+y_test),x=log(1+y_test),main = "True value vs Fitted",
xlab = "True value", ylab = "Residuals",ylim = c(-13,8))
qplot(y=lm_pred-log(1+y_test),x=log(1+y_test),main = "True value vs Residual",
xlab = "True value", ylab = "Residuals",ylim = c(-13,8))
theme_set(theme_gray(base_size = 18))
qplot(lm_pred-log(1+y_test),main = "residual distribution",
xlab = "residual",bins=30)
# underestimate is more serious in this model, meaning the inflated 0
# cause much bias of this model
# The assumption of poisson distribtuon did not improve the accuracy
# very much
qplot(y=lm_pred-log(1+y_test),x=log(1+y_test),main = "True value vs Residual",
xlab = "True value", ylab = "Residuals",ylim = c(-13,8))
# Question 2
library(ElemStatLearn)
library(caret)
intrain<-createDataPartition(y=spam$spam,p=0.2,list=FALSE)
train<-spam[intrain,]
test<-spam[-intrain,]
X_train = train[,-58]
y_train = as.numeric(train[,58])-1
train = cbind(X_train,y_train)
X_test = test[,-58]
y_test = as.numeric(test[,58])-1
library(gbm)
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=1,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 1000)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
# 5000 best, 0.01 shrinkage
acc_log = c()
# logistic loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="bernoulli",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 1000)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
acc_exp
acc_log
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 1000)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
acc_exp
which(acc_exp == max(acc_exp))
library(gbm)
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=1,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 1000)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.11,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 1000)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.1,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 1000)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 1000)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_log = c()
# logistic loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="bernoulli",
shrinkage=1,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 1000)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
which(acc_log == max(acc_log))
acc_log
acc_log = c()
# logistic loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="bernoulli",
shrinkage=0.1,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 1000)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
which(acc_log == max(acc_log))
acc_log
acc_log = c()
# logistic loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="bernoulli",
shrinkage=0.1,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 1000)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
which(acc_log == max(acc_log))
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=1,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 500)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.1,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 500)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(1000,10000,by = 500)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
seq(1000,10000,by = 500)
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=1,n.trees=10000,verbose = TRUE)
for (i in seq(500,10000,by = 500)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=1,n.trees=10000,verbose = TRUE)
for (i in seq(100,1000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.1,n.trees=10000,verbose = TRUE)
for (i in seq(100,1000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(100,2000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(100,3000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(100,3000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.1,n.trees=10000,verbose = TRUE)
for (i in seq(100,3000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_exp = c()
# exponential loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="adaboost",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(100,4000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
for (i in seq(100,10000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
acc_exp = c()
for (i in seq(100,10000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
for (i in seq(100,3000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp = c()
for (i in seq(100,3000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_exp = c(acc_exp,acc)
}
which(acc_exp == max(acc_exp))
acc_exp
acc_log = c()
# logistic loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="bernoulli",
shrinkage=1,n.trees=10000,verbose = TRUE)
for (i in seq(100,30000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
acc_log = c()
for (i in seq(100,3000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
which(acc_log == max(acc_log))
acc_log
for (i in seq(100,1000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
which(acc_log == max(acc_log))
acc_log = c()
set.seed(123)
for (i in seq(100,1000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
which(acc_log == max(acc_log))
acc_log
acc_log = c()
# logistic loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="bernoulli",
shrinkage=0.1,n.trees=10000,verbose = TRUE)
for (i in seq(100,1000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
which(acc_log == max(acc_log))
acc_log
acc_log = c()
# logistic loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="bernoulli",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(100,2000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
which(acc_log == max(acc_log))
acc_log
acc_log = c()
# logistic loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="bernoulli",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(100,3000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
which(acc_log == max(acc_log))
acc_log
acc_log = c()
# logistic loss
set.seed(123)
model_ada = gbm(y_train~., data=train,distribution="bernoulli",
shrinkage=0.01,n.trees=10000,verbose = TRUE)
for (i in seq(100,4000,by = 100)){
pred = predict(model_ada, X_test,n.trees = i,type="response")
pred_class = (pred>0.5)*1
confux = table(pred_class,y_test)
acc = (confux[1,1]+confux[2,2])/sum(confux)
acc_log = c(acc_log,acc)
}
which(acc_log == max(acc_log))
acc_log
