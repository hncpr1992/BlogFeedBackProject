{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "#model\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = pd.read_csv(\"../Data/newXTrain.csv\",header=0)\n",
    "testX = pd.read_csv(\"../Data/newXTest.csv\",header=0)\n",
    "y_train_log = pd.read_csv(\"../Data/y_train_log.csv\",header=None).as_matrix()\n",
    "y_test_log = pd.read_csv(\"../Data/y_test_log.csv\",header=None).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eva(test_pred, test_real):\n",
    "    return ((test_real-test_pred)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost with tree booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def testTrans(X_transTrain, X_transTest, y_train_log = y_train_log, y_test = y_test_log):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is for test accuracy of gradient boosting tree after Feature engineering\n",
    "    \"\"\"\n",
    "    # add weights to the predictions\n",
    "#     define loss function\n",
    "#     def mse(preds, dtrain):\n",
    "#         labels = dtrain.get_label()\n",
    "#         if labels > 10:\n",
    "#             grad = (preds - labels)*labels\n",
    "#             hess = labels\n",
    "#             return grad, hess\n",
    "#         else: \n",
    "#             grad = preds - labels\n",
    "#             hess = np.array([1]*len(grad))\n",
    "#             return grad, hess\n",
    "\n",
    "    RANDOM_STATE = 42\n",
    "    params = {\n",
    "        'min_child_weight': 1,\n",
    "        'eta': 0.01,\n",
    "        'colsample_bytree': 1,\n",
    "        'max_depth': 12,\n",
    "        'subsample': 0.2,\n",
    "        'reg_alpha': 1,\n",
    "        'gamma': 0.04,\n",
    "        'silent':True,\n",
    "        \"verbose_eval\":10,\n",
    "        \"eval_metric\":\"rmse\",\n",
    "        'seed': RANDOM_STATE\n",
    "    }\n",
    "\n",
    "    \n",
    "    # data preparation and model training \n",
    "    xgtrain = xgb.DMatrix(X_transTrain, label=y_train_log)\n",
    "    xgval = xgb.DMatrix(X_transTest, label=y_test_log)\n",
    "    xgtest = xgb.DMatrix(X_transTest)\n",
    "    gb_model = xgb.train(params, \n",
    "                         dtrain=xgtrain, \n",
    "                         evals=[(xgval,\"validation\")], \n",
    "                         early_stopping_rounds = 30,\n",
    "                         num_boost_round = 2000)\n",
    "    \n",
    "    # model prediction and evaluation\n",
    "    gb_pred = gb_model.predict(xgb.DMatrix(X_transTest))\n",
    "    return eva(gb_pred, y_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:1.04707\n",
      "Will train until validation-rmse hasn't improved in 30 rounds.\n",
      "[1]\tvalidation-rmse:1.04095\n",
      "[2]\tvalidation-rmse:1.03498\n",
      "[3]\tvalidation-rmse:1.02912\n",
      "[4]\tvalidation-rmse:1.02339\n",
      "[5]\tvalidation-rmse:1.01774\n",
      "[6]\tvalidation-rmse:1.01205\n",
      "[7]\tvalidation-rmse:1.00655\n",
      "[8]\tvalidation-rmse:1.0011\n",
      "[9]\tvalidation-rmse:0.995706\n",
      "[10]\tvalidation-rmse:0.990372\n",
      "[11]\tvalidation-rmse:0.985117\n",
      "[12]\tvalidation-rmse:0.980045\n",
      "[13]\tvalidation-rmse:0.975065\n",
      "[14]\tvalidation-rmse:0.969824\n",
      "[15]\tvalidation-rmse:0.965157\n",
      "[16]\tvalidation-rmse:0.960279\n",
      "[17]\tvalidation-rmse:0.955166\n",
      "[18]\tvalidation-rmse:0.950226\n",
      "[19]\tvalidation-rmse:0.945672\n",
      "[20]\tvalidation-rmse:0.940963\n",
      "[21]\tvalidation-rmse:0.936418\n",
      "[22]\tvalidation-rmse:0.931846\n",
      "[23]\tvalidation-rmse:0.927024\n",
      "[24]\tvalidation-rmse:0.922655\n",
      "[25]\tvalidation-rmse:0.918448\n",
      "[26]\tvalidation-rmse:0.914216\n",
      "[27]\tvalidation-rmse:0.910002\n",
      "[28]\tvalidation-rmse:0.905697\n",
      "[29]\tvalidation-rmse:0.901403\n",
      "[30]\tvalidation-rmse:0.897316\n",
      "[31]\tvalidation-rmse:0.893411\n",
      "[32]\tvalidation-rmse:0.889509\n",
      "[33]\tvalidation-rmse:0.885435\n",
      "[34]\tvalidation-rmse:0.881925\n",
      "[35]\tvalidation-rmse:0.877998\n",
      "[36]\tvalidation-rmse:0.874281\n",
      "[37]\tvalidation-rmse:0.870531\n",
      "[38]\tvalidation-rmse:0.866836\n",
      "[39]\tvalidation-rmse:0.863152\n",
      "[40]\tvalidation-rmse:0.85955\n",
      "[41]\tvalidation-rmse:0.856111\n",
      "[42]\tvalidation-rmse:0.852508\n",
      "[43]\tvalidation-rmse:0.849052\n",
      "[44]\tvalidation-rmse:0.84577\n",
      "[45]\tvalidation-rmse:0.842345\n",
      "[46]\tvalidation-rmse:0.838962\n",
      "[47]\tvalidation-rmse:0.835573\n",
      "[48]\tvalidation-rmse:0.832538\n",
      "[49]\tvalidation-rmse:0.829331\n",
      "[50]\tvalidation-rmse:0.82614\n",
      "[51]\tvalidation-rmse:0.82301\n",
      "[52]\tvalidation-rmse:0.819898\n",
      "[53]\tvalidation-rmse:0.816834\n",
      "[54]\tvalidation-rmse:0.813668\n",
      "[55]\tvalidation-rmse:0.810822\n",
      "[56]\tvalidation-rmse:0.807969\n",
      "[57]\tvalidation-rmse:0.805258\n",
      "[58]\tvalidation-rmse:0.802465\n",
      "[59]\tvalidation-rmse:0.799756\n",
      "[60]\tvalidation-rmse:0.796954\n",
      "[61]\tvalidation-rmse:0.794446\n",
      "[62]\tvalidation-rmse:0.791515\n",
      "[63]\tvalidation-rmse:0.788836\n",
      "[64]\tvalidation-rmse:0.786299\n",
      "[65]\tvalidation-rmse:0.783671\n",
      "[66]\tvalidation-rmse:0.78105\n",
      "[67]\tvalidation-rmse:0.778627\n",
      "[68]\tvalidation-rmse:0.776075\n",
      "[69]\tvalidation-rmse:0.77365\n",
      "[70]\tvalidation-rmse:0.771129\n",
      "[71]\tvalidation-rmse:0.768942\n",
      "[72]\tvalidation-rmse:0.766813\n",
      "[73]\tvalidation-rmse:0.764663\n",
      "[74]\tvalidation-rmse:0.76237\n",
      "[75]\tvalidation-rmse:0.760087\n",
      "[76]\tvalidation-rmse:0.757972\n",
      "[77]\tvalidation-rmse:0.755692\n",
      "[78]\tvalidation-rmse:0.753582\n",
      "[79]\tvalidation-rmse:0.751513\n",
      "[80]\tvalidation-rmse:0.74937\n",
      "[81]\tvalidation-rmse:0.747536\n",
      "[82]\tvalidation-rmse:0.745534\n",
      "[83]\tvalidation-rmse:0.743585\n",
      "[84]\tvalidation-rmse:0.741488\n",
      "[85]\tvalidation-rmse:0.739565\n",
      "[86]\tvalidation-rmse:0.737742\n",
      "[87]\tvalidation-rmse:0.735982\n",
      "[88]\tvalidation-rmse:0.734129\n",
      "[89]\tvalidation-rmse:0.732438\n",
      "[90]\tvalidation-rmse:0.730652\n",
      "[91]\tvalidation-rmse:0.728931\n",
      "[92]\tvalidation-rmse:0.727185\n",
      "[93]\tvalidation-rmse:0.725437\n",
      "[94]\tvalidation-rmse:0.723721\n",
      "[95]\tvalidation-rmse:0.722006\n",
      "[96]\tvalidation-rmse:0.720204\n",
      "[97]\tvalidation-rmse:0.718668\n",
      "[98]\tvalidation-rmse:0.71705\n",
      "[99]\tvalidation-rmse:0.715543\n",
      "[100]\tvalidation-rmse:0.713989\n",
      "[101]\tvalidation-rmse:0.712506\n",
      "[102]\tvalidation-rmse:0.711018\n",
      "[103]\tvalidation-rmse:0.709579\n",
      "[104]\tvalidation-rmse:0.708146\n",
      "[105]\tvalidation-rmse:0.706995\n",
      "[106]\tvalidation-rmse:0.705474\n",
      "[107]\tvalidation-rmse:0.704109\n",
      "[108]\tvalidation-rmse:0.702835\n",
      "[109]\tvalidation-rmse:0.701528\n",
      "[110]\tvalidation-rmse:0.700175\n",
      "[111]\tvalidation-rmse:0.698846\n",
      "[112]\tvalidation-rmse:0.69766\n",
      "[113]\tvalidation-rmse:0.696498\n",
      "[114]\tvalidation-rmse:0.695182\n",
      "[115]\tvalidation-rmse:0.694053\n",
      "[116]\tvalidation-rmse:0.692818\n",
      "[117]\tvalidation-rmse:0.691543\n",
      "[118]\tvalidation-rmse:0.69025\n",
      "[119]\tvalidation-rmse:0.689163\n",
      "[120]\tvalidation-rmse:0.688031\n",
      "[121]\tvalidation-rmse:0.686888\n",
      "[122]\tvalidation-rmse:0.685726\n",
      "[123]\tvalidation-rmse:0.684568\n",
      "[124]\tvalidation-rmse:0.683579\n",
      "[125]\tvalidation-rmse:0.682572\n",
      "[126]\tvalidation-rmse:0.68143\n",
      "[127]\tvalidation-rmse:0.680342\n",
      "[128]\tvalidation-rmse:0.679364\n",
      "[129]\tvalidation-rmse:0.678269\n",
      "[130]\tvalidation-rmse:0.677342\n",
      "[131]\tvalidation-rmse:0.676306\n",
      "[132]\tvalidation-rmse:0.675393\n",
      "[133]\tvalidation-rmse:0.674471\n",
      "[134]\tvalidation-rmse:0.673524\n",
      "[135]\tvalidation-rmse:0.672484\n",
      "[136]\tvalidation-rmse:0.67168\n",
      "[137]\tvalidation-rmse:0.670693\n",
      "[138]\tvalidation-rmse:0.669878\n",
      "[139]\tvalidation-rmse:0.668846\n",
      "[140]\tvalidation-rmse:0.667987\n",
      "[141]\tvalidation-rmse:0.667124\n",
      "[142]\tvalidation-rmse:0.666368\n",
      "[143]\tvalidation-rmse:0.665622\n",
      "[144]\tvalidation-rmse:0.664781\n",
      "[145]\tvalidation-rmse:0.664017\n",
      "[146]\tvalidation-rmse:0.663307\n",
      "[147]\tvalidation-rmse:0.662425\n",
      "[148]\tvalidation-rmse:0.661791\n",
      "[149]\tvalidation-rmse:0.660944\n",
      "[150]\tvalidation-rmse:0.660077\n",
      "[151]\tvalidation-rmse:0.659345\n",
      "[152]\tvalidation-rmse:0.658497\n",
      "[153]\tvalidation-rmse:0.657765\n",
      "[154]\tvalidation-rmse:0.657104\n",
      "[155]\tvalidation-rmse:0.656405\n",
      "[156]\tvalidation-rmse:0.65569\n",
      "[157]\tvalidation-rmse:0.654912\n",
      "[158]\tvalidation-rmse:0.654271\n",
      "[159]\tvalidation-rmse:0.653594\n",
      "[160]\tvalidation-rmse:0.652991\n",
      "[161]\tvalidation-rmse:0.652354\n",
      "[162]\tvalidation-rmse:0.651677\n",
      "[163]\tvalidation-rmse:0.650864\n",
      "[164]\tvalidation-rmse:0.650231\n",
      "[165]\tvalidation-rmse:0.64958\n",
      "[166]\tvalidation-rmse:0.648985\n",
      "[167]\tvalidation-rmse:0.648488\n",
      "[168]\tvalidation-rmse:0.647863\n",
      "[169]\tvalidation-rmse:0.647346\n",
      "[170]\tvalidation-rmse:0.646816\n",
      "[171]\tvalidation-rmse:0.646334\n",
      "[172]\tvalidation-rmse:0.645816\n",
      "[173]\tvalidation-rmse:0.645155\n",
      "[174]\tvalidation-rmse:0.644529\n",
      "[175]\tvalidation-rmse:0.644018\n",
      "[176]\tvalidation-rmse:0.64361\n",
      "[177]\tvalidation-rmse:0.643105\n",
      "[178]\tvalidation-rmse:0.642653\n",
      "[179]\tvalidation-rmse:0.642143\n",
      "[180]\tvalidation-rmse:0.641594\n",
      "[181]\tvalidation-rmse:0.641213\n",
      "[182]\tvalidation-rmse:0.640767\n",
      "[183]\tvalidation-rmse:0.640392\n",
      "[184]\tvalidation-rmse:0.639998\n",
      "[185]\tvalidation-rmse:0.63951\n",
      "[186]\tvalidation-rmse:0.639062\n",
      "[187]\tvalidation-rmse:0.638598\n",
      "[188]\tvalidation-rmse:0.638218\n",
      "[189]\tvalidation-rmse:0.637743\n",
      "[190]\tvalidation-rmse:0.637361\n",
      "[191]\tvalidation-rmse:0.636888\n",
      "[192]\tvalidation-rmse:0.636492\n",
      "[193]\tvalidation-rmse:0.636095\n",
      "[194]\tvalidation-rmse:0.635677\n",
      "[195]\tvalidation-rmse:0.635292\n",
      "[196]\tvalidation-rmse:0.634984\n",
      "[197]\tvalidation-rmse:0.634636\n",
      "[198]\tvalidation-rmse:0.634332\n",
      "[199]\tvalidation-rmse:0.634048\n",
      "[200]\tvalidation-rmse:0.633621\n",
      "[201]\tvalidation-rmse:0.633385\n",
      "[202]\tvalidation-rmse:0.632985\n",
      "[203]\tvalidation-rmse:0.632643\n",
      "[204]\tvalidation-rmse:0.632318\n",
      "[205]\tvalidation-rmse:0.631909\n",
      "[206]\tvalidation-rmse:0.631607\n",
      "[207]\tvalidation-rmse:0.631306\n",
      "[208]\tvalidation-rmse:0.631029\n",
      "[209]\tvalidation-rmse:0.630776\n",
      "[210]\tvalidation-rmse:0.630424\n",
      "[211]\tvalidation-rmse:0.630181\n",
      "[212]\tvalidation-rmse:0.630016\n",
      "[213]\tvalidation-rmse:0.629735\n",
      "[214]\tvalidation-rmse:0.629435\n",
      "[215]\tvalidation-rmse:0.629201\n",
      "[216]\tvalidation-rmse:0.629039\n",
      "[217]\tvalidation-rmse:0.628708\n",
      "[218]\tvalidation-rmse:0.628392\n",
      "[219]\tvalidation-rmse:0.628195\n",
      "[220]\tvalidation-rmse:0.627979\n",
      "[221]\tvalidation-rmse:0.627674\n",
      "[222]\tvalidation-rmse:0.627428\n",
      "[223]\tvalidation-rmse:0.627151\n",
      "[224]\tvalidation-rmse:0.626961\n",
      "[225]\tvalidation-rmse:0.626811\n",
      "[226]\tvalidation-rmse:0.626418\n",
      "[227]\tvalidation-rmse:0.626115\n",
      "[228]\tvalidation-rmse:0.625856\n",
      "[229]\tvalidation-rmse:0.625636\n",
      "[230]\tvalidation-rmse:0.625404\n",
      "[231]\tvalidation-rmse:0.625263\n",
      "[232]\tvalidation-rmse:0.624953\n",
      "[233]\tvalidation-rmse:0.624742\n",
      "[234]\tvalidation-rmse:0.624513\n",
      "[235]\tvalidation-rmse:0.62435\n",
      "[236]\tvalidation-rmse:0.624117\n",
      "[237]\tvalidation-rmse:0.623888\n",
      "[238]\tvalidation-rmse:0.62371\n",
      "[239]\tvalidation-rmse:0.623553\n",
      "[240]\tvalidation-rmse:0.623276\n",
      "[241]\tvalidation-rmse:0.623046\n",
      "[242]\tvalidation-rmse:0.622846\n",
      "[243]\tvalidation-rmse:0.6227\n",
      "[244]\tvalidation-rmse:0.622614\n",
      "[245]\tvalidation-rmse:0.622409\n",
      "[246]\tvalidation-rmse:0.622239\n",
      "[247]\tvalidation-rmse:0.622092\n",
      "[248]\tvalidation-rmse:0.622011\n",
      "[249]\tvalidation-rmse:0.621861\n",
      "[250]\tvalidation-rmse:0.621676\n",
      "[251]\tvalidation-rmse:0.621428\n",
      "[252]\tvalidation-rmse:0.621312\n",
      "[253]\tvalidation-rmse:0.62111\n",
      "[254]\tvalidation-rmse:0.620936\n",
      "[255]\tvalidation-rmse:0.62079\n",
      "[256]\tvalidation-rmse:0.620595\n",
      "[257]\tvalidation-rmse:0.620489\n",
      "[258]\tvalidation-rmse:0.620347\n",
      "[259]\tvalidation-rmse:0.620118\n",
      "[260]\tvalidation-rmse:0.619995\n",
      "[261]\tvalidation-rmse:0.619824\n",
      "[262]\tvalidation-rmse:0.619553\n",
      "[263]\tvalidation-rmse:0.619412\n",
      "[264]\tvalidation-rmse:0.61926\n",
      "[265]\tvalidation-rmse:0.619208\n",
      "[266]\tvalidation-rmse:0.619019\n",
      "[267]\tvalidation-rmse:0.618916\n",
      "[268]\tvalidation-rmse:0.618821\n",
      "[269]\tvalidation-rmse:0.618581\n",
      "[270]\tvalidation-rmse:0.618408\n",
      "[271]\tvalidation-rmse:0.618306\n",
      "[272]\tvalidation-rmse:0.618114\n",
      "[273]\tvalidation-rmse:0.617934\n",
      "[274]\tvalidation-rmse:0.617771\n",
      "[275]\tvalidation-rmse:0.617583\n",
      "[276]\tvalidation-rmse:0.617322\n",
      "[277]\tvalidation-rmse:0.617168\n",
      "[278]\tvalidation-rmse:0.617007\n",
      "[279]\tvalidation-rmse:0.616919\n",
      "[280]\tvalidation-rmse:0.61689\n",
      "[281]\tvalidation-rmse:0.616841\n",
      "[282]\tvalidation-rmse:0.616691\n",
      "[283]\tvalidation-rmse:0.616606\n",
      "[284]\tvalidation-rmse:0.616497\n",
      "[285]\tvalidation-rmse:0.616457\n",
      "[286]\tvalidation-rmse:0.616361\n",
      "[287]\tvalidation-rmse:0.616287\n",
      "[288]\tvalidation-rmse:0.616181\n",
      "[289]\tvalidation-rmse:0.616093\n",
      "[290]\tvalidation-rmse:0.616039\n",
      "[291]\tvalidation-rmse:0.615962\n",
      "[292]\tvalidation-rmse:0.615861\n",
      "[293]\tvalidation-rmse:0.615729\n",
      "[294]\tvalidation-rmse:0.615588\n",
      "[295]\tvalidation-rmse:0.615565\n",
      "[296]\tvalidation-rmse:0.615453\n",
      "[297]\tvalidation-rmse:0.615503\n",
      "[298]\tvalidation-rmse:0.615386\n",
      "[299]\tvalidation-rmse:0.615329\n",
      "[300]\tvalidation-rmse:0.615258\n",
      "[301]\tvalidation-rmse:0.615091\n",
      "[302]\tvalidation-rmse:0.614994\n",
      "[303]\tvalidation-rmse:0.614892\n",
      "[304]\tvalidation-rmse:0.614873\n",
      "[305]\tvalidation-rmse:0.614788\n",
      "[306]\tvalidation-rmse:0.614812\n",
      "[307]\tvalidation-rmse:0.6148\n",
      "[308]\tvalidation-rmse:0.614736\n",
      "[309]\tvalidation-rmse:0.614609\n",
      "[310]\tvalidation-rmse:0.614551\n",
      "[311]\tvalidation-rmse:0.614505\n",
      "[312]\tvalidation-rmse:0.614391\n",
      "[313]\tvalidation-rmse:0.614398\n",
      "[314]\tvalidation-rmse:0.6144\n",
      "[315]\tvalidation-rmse:0.614339\n",
      "[316]\tvalidation-rmse:0.614286\n",
      "[317]\tvalidation-rmse:0.61421\n",
      "[318]\tvalidation-rmse:0.614075\n",
      "[319]\tvalidation-rmse:0.61386\n",
      "[320]\tvalidation-rmse:0.613711\n",
      "[321]\tvalidation-rmse:0.613564\n",
      "[322]\tvalidation-rmse:0.613452\n",
      "[323]\tvalidation-rmse:0.613403\n",
      "[324]\tvalidation-rmse:0.613311\n",
      "[325]\tvalidation-rmse:0.613123\n",
      "[326]\tvalidation-rmse:0.612998\n",
      "[327]\tvalidation-rmse:0.612867\n",
      "[328]\tvalidation-rmse:0.612822\n",
      "[329]\tvalidation-rmse:0.612735\n",
      "[330]\tvalidation-rmse:0.612638\n",
      "[331]\tvalidation-rmse:0.612673\n",
      "[332]\tvalidation-rmse:0.612596\n",
      "[333]\tvalidation-rmse:0.612483\n",
      "[334]\tvalidation-rmse:0.612496\n",
      "[335]\tvalidation-rmse:0.612403\n",
      "[336]\tvalidation-rmse:0.612336\n",
      "[337]\tvalidation-rmse:0.61233\n",
      "[338]\tvalidation-rmse:0.612238\n",
      "[339]\tvalidation-rmse:0.612188\n",
      "[340]\tvalidation-rmse:0.612058\n",
      "[341]\tvalidation-rmse:0.611953\n",
      "[342]\tvalidation-rmse:0.611846\n",
      "[343]\tvalidation-rmse:0.611843\n",
      "[344]\tvalidation-rmse:0.611839\n",
      "[345]\tvalidation-rmse:0.611782\n",
      "[346]\tvalidation-rmse:0.611744\n",
      "[347]\tvalidation-rmse:0.61169\n",
      "[348]\tvalidation-rmse:0.611733\n",
      "[349]\tvalidation-rmse:0.611717\n",
      "[350]\tvalidation-rmse:0.611684\n",
      "[351]\tvalidation-rmse:0.611553\n",
      "[352]\tvalidation-rmse:0.611468\n",
      "[353]\tvalidation-rmse:0.61141\n",
      "[354]\tvalidation-rmse:0.611296\n",
      "[355]\tvalidation-rmse:0.611267\n",
      "[356]\tvalidation-rmse:0.611177\n",
      "[357]\tvalidation-rmse:0.611136\n",
      "[358]\tvalidation-rmse:0.61105\n",
      "[359]\tvalidation-rmse:0.611104\n",
      "[360]\tvalidation-rmse:0.611067\n",
      "[361]\tvalidation-rmse:0.610998\n",
      "[362]\tvalidation-rmse:0.611008\n",
      "[363]\tvalidation-rmse:0.611004\n",
      "[364]\tvalidation-rmse:0.610947\n",
      "[365]\tvalidation-rmse:0.610896\n",
      "[366]\tvalidation-rmse:0.610897\n",
      "[367]\tvalidation-rmse:0.610902\n",
      "[368]\tvalidation-rmse:0.610838\n",
      "[369]\tvalidation-rmse:0.610874\n",
      "[370]\tvalidation-rmse:0.61082\n",
      "[371]\tvalidation-rmse:0.610768\n",
      "[372]\tvalidation-rmse:0.610719\n",
      "[373]\tvalidation-rmse:0.6107\n",
      "[374]\tvalidation-rmse:0.61058\n",
      "[375]\tvalidation-rmse:0.610579\n",
      "[376]\tvalidation-rmse:0.610542\n",
      "[377]\tvalidation-rmse:0.610516\n",
      "[378]\tvalidation-rmse:0.610466\n",
      "[379]\tvalidation-rmse:0.610447\n",
      "[380]\tvalidation-rmse:0.610329\n",
      "[381]\tvalidation-rmse:0.61034\n",
      "[382]\tvalidation-rmse:0.61034\n",
      "[383]\tvalidation-rmse:0.610305\n",
      "[384]\tvalidation-rmse:0.610414\n",
      "[385]\tvalidation-rmse:0.610366\n",
      "[386]\tvalidation-rmse:0.610259\n",
      "[387]\tvalidation-rmse:0.610285\n",
      "[388]\tvalidation-rmse:0.610261\n",
      "[389]\tvalidation-rmse:0.610249\n",
      "[390]\tvalidation-rmse:0.610223\n",
      "[391]\tvalidation-rmse:0.610257\n",
      "[392]\tvalidation-rmse:0.6102\n",
      "[393]\tvalidation-rmse:0.61017\n",
      "[394]\tvalidation-rmse:0.610087\n",
      "[395]\tvalidation-rmse:0.610073\n",
      "[396]\tvalidation-rmse:0.609987\n",
      "[397]\tvalidation-rmse:0.609982\n",
      "[398]\tvalidation-rmse:0.609992\n",
      "[399]\tvalidation-rmse:0.609991\n",
      "[400]\tvalidation-rmse:0.61003\n",
      "[401]\tvalidation-rmse:0.609998\n",
      "[402]\tvalidation-rmse:0.610048\n",
      "[403]\tvalidation-rmse:0.609995\n",
      "[404]\tvalidation-rmse:0.609968\n",
      "[405]\tvalidation-rmse:0.609907\n",
      "[406]\tvalidation-rmse:0.609851\n",
      "[407]\tvalidation-rmse:0.609849\n",
      "[408]\tvalidation-rmse:0.609905\n",
      "[409]\tvalidation-rmse:0.609911\n",
      "[410]\tvalidation-rmse:0.609907\n",
      "[411]\tvalidation-rmse:0.609896\n",
      "[412]\tvalidation-rmse:0.609879\n",
      "[413]\tvalidation-rmse:0.6098\n",
      "[414]\tvalidation-rmse:0.609786\n",
      "[415]\tvalidation-rmse:0.6098\n",
      "[416]\tvalidation-rmse:0.609783\n",
      "[417]\tvalidation-rmse:0.609715\n",
      "[418]\tvalidation-rmse:0.60971\n",
      "[419]\tvalidation-rmse:0.609643\n",
      "[420]\tvalidation-rmse:0.609646\n",
      "[421]\tvalidation-rmse:0.609643\n",
      "[422]\tvalidation-rmse:0.609579\n",
      "[423]\tvalidation-rmse:0.6096\n",
      "[424]\tvalidation-rmse:0.609644\n",
      "[425]\tvalidation-rmse:0.609634\n",
      "[426]\tvalidation-rmse:0.609526\n",
      "[427]\tvalidation-rmse:0.609538\n",
      "[428]\tvalidation-rmse:0.609576\n",
      "[429]\tvalidation-rmse:0.609521\n",
      "[430]\tvalidation-rmse:0.609468\n",
      "[431]\tvalidation-rmse:0.609514\n",
      "[432]\tvalidation-rmse:0.609488\n",
      "[433]\tvalidation-rmse:0.609483\n",
      "[434]\tvalidation-rmse:0.60951\n",
      "[435]\tvalidation-rmse:0.609576\n",
      "[436]\tvalidation-rmse:0.609578\n",
      "[437]\tvalidation-rmse:0.609536\n",
      "[438]\tvalidation-rmse:0.609558\n",
      "[439]\tvalidation-rmse:0.609571\n",
      "[440]\tvalidation-rmse:0.609622\n",
      "[441]\tvalidation-rmse:0.609617\n",
      "[442]\tvalidation-rmse:0.609616\n",
      "[443]\tvalidation-rmse:0.609535\n",
      "[444]\tvalidation-rmse:0.609525\n",
      "[445]\tvalidation-rmse:0.609521\n",
      "[446]\tvalidation-rmse:0.609459\n",
      "[447]\tvalidation-rmse:0.60944\n",
      "[448]\tvalidation-rmse:0.609413\n",
      "[449]\tvalidation-rmse:0.609401\n",
      "[450]\tvalidation-rmse:0.609316\n",
      "[451]\tvalidation-rmse:0.609269\n",
      "[452]\tvalidation-rmse:0.609337\n",
      "[453]\tvalidation-rmse:0.609375\n",
      "[454]\tvalidation-rmse:0.609369\n",
      "[455]\tvalidation-rmse:0.609446\n",
      "[456]\tvalidation-rmse:0.609444\n",
      "[457]\tvalidation-rmse:0.609475\n",
      "[458]\tvalidation-rmse:0.60946\n",
      "[459]\tvalidation-rmse:0.609544\n",
      "[460]\tvalidation-rmse:0.609575\n",
      "[461]\tvalidation-rmse:0.609548\n",
      "[462]\tvalidation-rmse:0.609563\n",
      "[463]\tvalidation-rmse:0.609561\n",
      "[464]\tvalidation-rmse:0.609568\n",
      "[465]\tvalidation-rmse:0.609589\n",
      "[466]\tvalidation-rmse:0.609582\n",
      "[467]\tvalidation-rmse:0.6096\n",
      "[468]\tvalidation-rmse:0.609566\n",
      "[469]\tvalidation-rmse:0.609648\n",
      "[470]\tvalidation-rmse:0.609621\n",
      "[471]\tvalidation-rmse:0.609657\n",
      "[472]\tvalidation-rmse:0.609612\n",
      "[473]\tvalidation-rmse:0.60966\n",
      "[474]\tvalidation-rmse:0.60972\n",
      "[475]\tvalidation-rmse:0.609641\n",
      "[476]\tvalidation-rmse:0.609689\n",
      "[477]\tvalidation-rmse:0.609669\n",
      "[478]\tvalidation-rmse:0.609629\n",
      "[479]\tvalidation-rmse:0.609614\n",
      "[480]\tvalidation-rmse:0.609584\n",
      "[481]\tvalidation-rmse:0.609612\n",
      "Stopping. Best iteration:\n",
      "[451]\tvalidation-rmse:0.609269\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7841574467661661"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTrans(X_transTrain=trainX, X_transTest=testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost with linear booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testLin(X_transTrain, X_transTest, y_train_log = y_train_log, y_test = y_test_log):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is for test accuracy of gradient boosting tree after Feature engineering\n",
    "    \"\"\"\n",
    "    # add weights to the predictions\n",
    "#     define loss function\n",
    "#     def mse(preds, dtrain):\n",
    "#         labels = dtrain.get_label()\n",
    "#         if labels > 10:\n",
    "#             grad = (preds - labels)*labels\n",
    "#             hess = labels\n",
    "#             return grad, hess\n",
    "#         else: \n",
    "#             grad = preds - labels\n",
    "#             hess = np.array([1]*len(grad))\n",
    "#             return grad, hess\n",
    "\n",
    "    RANDOM_STATE = 42\n",
    "    params = {\n",
    "\n",
    "        'colsample_bytree': 1,\n",
    "        'max_depth': 12,\n",
    "        'subsample': 0.2,\n",
    "        'reg_alpha': 1,\n",
    "        'gamma': 0.04,\n",
    "        'silent':True,\n",
    "        \"verbose_eval\":10,\n",
    "        \"eval_metric\":\"rmse\",\n",
    "        'seed': RANDOM_STATE\n",
    "    }\n",
    "\n",
    "    \n",
    "    # data preparation and model training \n",
    "    xgtrain = xgb.DMatrix(X_transTrain, label=y_train_log)\n",
    "    xgval = xgb.DMatrix(X_transTest, label=y_test_log)\n",
    "    xgtest = xgb.DMatrix(X_transTest)\n",
    "    gb_model = xgb.train(params, \n",
    "                         dtrain=xgtrain, \n",
    "                         evals=[(xgval,\"validation\")], \n",
    "                         early_stopping_rounds = 30,\n",
    "                         num_boost_round = 2000)\n",
    "    \n",
    "    # model prediction and evaluation\n",
    "    gb_pred = gb_model.predict(xgb.DMatrix(X_transTest))\n",
    "    return eva(gb_pred, y_test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ensemble with boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "## cv-folds\n",
    "nfolds = 10\n",
    "folds = KFold(len(y_train_log), n_folds = nfolds, shuffle = True, random_state = 111)\n",
    "\n",
    "nepochs = 55\n",
    "model_group = []\n",
    "pred = []\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "for (Tr, Te) in folds:\n",
    "    train_x = X_train[Tr] \n",
    "    train_y = y_train[Tr]\n",
    "    test_x = X_train[Te]\n",
    "    test_y = y_train[Te]\n",
    "    train_y_log = np.log(train_y+200)\n",
    "    \n",
    "    model = NN()\n",
    "    # model will stop if overfit on the test data\n",
    "    model.fit(train_x, train_y_log, validation_data = (test_x,test_y), nb_epoch=nepochs, batch_size=300,\n",
    "             callbacks=[early_stopping])\n",
    "    y_test_pred_log = model.predict(X_test)\n",
    "    y_test_pred_log = y_test_pred_log.reshape([y_test_pred_log.shape[0],])\n",
    "    y_test_pred = np.exp(y_test_pred_log)-200\n",
    "    pred.append(y_test_pred)\n",
    "    model_group.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
